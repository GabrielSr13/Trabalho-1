# -*- coding: utf-8 -*-
"""GPU Project.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1ohxF6zh1dFjzRQWVfxwQQGslSsFziDwj
"""

from numba import cuda

import numpy

from numpy import *

@cuda.jit
def my_kernel(io_array, o_array):
    # Thread id in a 1D block
    tx = cuda.threadIdx.x
    # Block id in a 1D grid
    ty = cuda.blockIdx.x
    # Block width, i.e. number of threads per block
    bw = cuda.blockDim.x
    
    # Compute flattened index inside the array
    pos = tx + ty * bw

    num = 0
    count = 0  
    i = 0
    while( i < io_array.size ):
      num = io_array[i]
      for n in io_array:
        if num == n:
          count = count + 1
      o_array[num-1] = count
      count = 0
      i = i + 1  
      

# vetor com números
data = random.randint(1,11, size=(100))

print(data)
o_array = numpy.empty([10])

# números de threads por bloco
threads_per_block = 32

# número de blocos por grid
blocks_per_grid = ( data.size + (threads_per_block - 1) )

# iniciando o kernel
my_kernel[blocks_per_grid, threads_per_block](data, o_array)

# mostra o resultado
print(o_array)



